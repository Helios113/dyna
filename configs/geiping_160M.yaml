defaults:
  - _self_
  - scheduler_config: wsld
  - callbacks: default_100
  - data_config: smoll
  - optimizer_config: adamw
  - fsdp_config: null

model_config:
  execution_mode: geiping_std
  d_model: 768
  d_ffn: 3072
  n_repeats: 1
  n_heads: 12
  d_head: 64
  n_layers: 4
  vocab_size: 50368
  max_seq_len: 1024
  n_expert_shared_attn: 0
  n_expert_shared_ffn: 0
  collect_reg_loss: False
  enable_early_exit: False
  norm_structure: pre
  rescaling_method: none
  sample_iterations: True

# class NormStructure(Enum):
#     Peri = 0
#     Pre = 1
#     Post = 2
#     moeut = 3
# class RescaleMethod(Enum):
#     none = 0
#     cum_avg_prot_emb = 1
#     cum_avg_no_prot_emb = 2
#     sqrt_prot_emb = 3
#     sqrt_no_prot_emb = 4
    
train:
  max_duration: "3171ba"
  warmup: "634ba"
  cooldown: "634ba"
  device_train_batch_size: 1024


trainer_config:
  run_name: "geiping"
  max_duration: ${train.max_duration}
  train_dataloader_label: "train"
  device_train_microbatch_size: auto
  precision: "amp_bf16"
  device: "gpu"
  save_folder: "s3://loop-llm/dyna/"
  save_interval: "100ba"

