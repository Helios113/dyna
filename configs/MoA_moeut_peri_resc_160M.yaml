defaults:
  - _self_
  - scheduler_config: wsld
  - callbacks: default_100
  - data_config: smoll
  - optimizer_config: adamw
  - fsdp_config: null

model_config:
  execution_mode: moe
  d_model: 768
  n_repeats: 6
  n_heads: 3
  n_experts_ffn: 192
  n_experts_attn: 10
  d_head: 128
  k_ffn: 12
  k_attn: 2
  d_expert_ffn: 128
  n_layers: 2
  vocab_size: 50368
  max_seq_len: 1024
  n_expert_shared_attn: 0
  n_expert_shared_ffn: 0
  collect_reg_loss: False
  enable_early_exit: False
  norm_structure: "peri"
  rescaling_method: "cum_avg_prot_emb"

train:
  max_duration: "3171ba"
  warmup: "634ba"
  cooldown: "634ba"
  device_train_batch_size: 1024

trainer_config:
  run_name: "base"
  max_duration: ${train.max_duration}
  train_dataloader_label: "train"
  device_train_microbatch_size: auto
  precision: "amp_bf16"
  device: "gpu"
  save_folder: "s3://loop-llm/dyna/"
  save_interval: "100ba"
